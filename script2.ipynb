{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This place has the best dumplings I've ever ha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Came here on a weekend visit to NY, my friend ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The best soup dumplings in NYC! There is no ot...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was so disappointed with my visit to Joes. N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So much fun!  we stayed at Hotel 50\\r\\nRight n...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  This place has the best dumplings I've ever ha...       5\n",
       "1  Came here on a weekend visit to NY, my friend ...       4\n",
       "2  The best soup dumplings in NYC! There is no ot...       5\n",
       "3  I was so disappointed with my visit to Joes. N...       1\n",
       "4  So much fun!  we stayed at Hotel 50\\r\\nRight n...       5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('restaurant_reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\A S U S\\AppData\\Local\\Temp\\ipykernel_14572\\1311990623.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  text = re.sub('\\s+', ' ', text)  # Replace multiple whitespace characters with a single space\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)  # Keep only lowercase and uppercase letters\n",
    "    text = re.sub('\\s+', ' ', text)  # Replace multiple whitespace characters with a single space\n",
    "    text = nlp(text)\n",
    "    text = [word.lemma_ for word in text if not word.is_stop and not word.is_punct and not word.like_num]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom tokenizer\n",
    "def custom_tokenizer(text):\n",
    "    # Use NLTK's word_tokenize function to tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Return the tokens\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a new feature 'Length' and 'Sentiment'\n",
    "data['Length'] = data['Review'].apply(len)\n",
    "data['Sentiment'] = data['Rating'].apply(lambda x: 'Positive' if x >= 4 else 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = tfidf_vectorizer.fit_transform(data['Tokenized_Review'].apply(' '.join))\n",
    "# y = data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {'LR' : LogisticRegression(), 'RF' : RandomForestClassifier(), 'NB' : MultinomialNB(), 'SVM' : SVC()}\n",
    "# vectorizers = {'TF-IDF' : TfidfVectorizer()}\n",
    "\n",
    "# parameters = {'LR' : {'C' : [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "#                 'RF' : {'n_estimators' : [50, 100, 200]},\n",
    "#                 'NB' : {'alpha' : [0.5, 1, 2]},\n",
    "#                 'SVM' : {'C' : [0.1, 1, 10], 'gamma' : [0.1, 1, 10]}}\n",
    "# results = []\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     for vectorizer_name, vectorizer in vectorizers.items():\n",
    "#         pipeline = GridSearchCV(model, parameters[model_name], cv=5)\n",
    "#         pipeline.fit(vectorizer.fit_transform(data['Tokenized_Review'].apply(' '.join)), data['Sentiment'])\n",
    "#         results.append({'model' : model_name, 'vectorizer' : vectorizer_name, 'best_params' : pipeline.best_params_, 'best_score' : pipeline.best_score_})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame(results)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets train the model\n",
    "# model = LogisticRegression(C=1)\n",
    "# model.fit(X_train, y_train)\n",
    "# # use k-fold cross validation to evaluate the model\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "# print('Cross-validation scores: {}'.format(scores))\n",
    "# print('Average cross-validation score: {:.2f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets try svm\n",
    "# model = SVC(C=10, gamma=1)\n",
    "# model.fit(X_train, y_train)\n",
    "# # use k-fold cross validation to evaluate the model\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "# print('Cross-validation scores: {}'.format(scores))\n",
    "# print('Average cross-validation score: {:.2f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Positive    5042\n",
       "Negative    2238\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets extract equal number of positive and negative reviews\n",
    "positive_reviews = data[data['Sentiment'] == 'Positive'].sample(2238)\n",
    "negative_reviews = data[data['Sentiment'] == 'Negative'].sample(2238)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Positive    2238\n",
       "Negative    2238\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([positive_reviews, negative_reviews]).reset_index(drop=True)\n",
    "data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This place is ridiculous.  Great soup dumpling...</td>\n",
       "      <td>5</td>\n",
       "      <td>177</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stopped in the other day while in Chinatown. W...</td>\n",
       "      <td>4</td>\n",
       "      <td>866</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In general, typical Americanized Chinese food....</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOUP DUMPLINGS!! it's just delicious, I've eat...</td>\n",
       "      <td>5</td>\n",
       "      <td>331</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the kind place you imagine after readi...</td>\n",
       "      <td>5</td>\n",
       "      <td>971</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  Length Sentiment\n",
       "0  This place is ridiculous.  Great soup dumpling...       5     177  Positive\n",
       "1  Stopped in the other day while in Chinatown. W...       4     866  Positive\n",
       "2  In general, typical Americanized Chinese food....       4     136  Positive\n",
       "3  SOUP DUMPLINGS!! it's just delicious, I've eat...       5     331  Positive\n",
       "4  This is the kind place you imagine after readi...       5     971  Positive"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review'] = data['Review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>place ridiculous great soup dumpling great sta...</td>\n",
       "      <td>5</td>\n",
       "      <td>177</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stop day chinatown want try eat visit new york...</td>\n",
       "      <td>4</td>\n",
       "      <td>866</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>general typical americanized chinese food good...</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soup dumpling s delicious ve eat thing soup du...</td>\n",
       "      <td>5</td>\n",
       "      <td>331</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kind place imagine read book review visit real...</td>\n",
       "      <td>5</td>\n",
       "      <td>971</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  Length Sentiment\n",
       "0  place ridiculous great soup dumpling great sta...       5     177  Positive\n",
       "1  stop day chinatown want try eat visit new york...       4     866  Positive\n",
       "2  general typical americanized chinese food good...       4     136  Positive\n",
       "3  soup dumpling s delicious ve eat thing soup du...       5     331  Positive\n",
       "4  kind place imagine read book review visit real...       5     971  Positive"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data into numerical features using TF-IDF\n",
    "tfidf = TfidfVectorizer(tokenizer=custom_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A S U S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = tfidf.fit_transform(data['Review'])\n",
    "y = data['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets train the model\n",
    "# models = {'LR' : LogisticRegression(), 'RF' : RandomForestClassifier(), 'NB' : MultinomialNB(), 'SVM' : SVC()}\n",
    "# vectorizers = {'TF-IDF' : TfidfVectorizer()}\n",
    "\n",
    "# parameters = {'LR' : {'C' : [0.001, 0.01, 0.1, 0.4]},\n",
    "#                 'RF' : {'n_estimators' : [50, 100, 200], 'max_depth' : [25, 30, 32, 35, 38]},\n",
    "#                 'NB' : {'alpha' : [0.5, 1, 2]},\n",
    "#                 'SVM' : {'C' : [0.1, 1, 10], 'gamma' : [0.1, 1, 2], 'kernel' : ['linear', 'rbf']}}\n",
    "# results = []\n",
    "\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     for vectorizer_name, vectorizer in vectorizers.items():\n",
    "#         pipeline = GridSearchCV(model, parameters[model_name], cv=5)\n",
    "#         pipeline.fit(vectorizer.fit_transform(data['Review']), data['Sentiment'])\n",
    "#         results.append({'model' : model_name, 'vectorizer' : vectorizer_name, 'best_params' : pipeline.best_params_, 'best_score' : pipeline.best_score_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame(results)\n",
    "# # lets see the params of random forest\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.80167598 0.81703911 0.80586592 0.84636872 0.81843575]\n",
      "Average cross-validation score: 0.82\n"
     ]
    }
   ],
   "source": [
    "# lets try naive bayes \n",
    "model = MultinomialNB(alpha=2)\n",
    "model.fit(X_train, y_train)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "print('Cross-validation scores: {}'.format(scores))\n",
    "print('Average cross-validation score: {:.2f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[353,  81],\n",
       "       [ 90, 372]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SVC(C=10, gamma=1, kernel='rbf')\n",
    "# model.fit(X_train, y_train)\n",
    "# scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "# print('Cross-validation scores: {}'.format(scores))\n",
    "# print('Average cross-validation score: {:.2f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:32: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\A S U S\\AppData\\Local\\Temp\\ipykernel_14572\\2475100309.py:32: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  text = re.sub('\\s+', ' ', text)  # Replace multiple whitespace characters with a single space\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import streamlit as st\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, tokenizer=word_tokenize):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = []\n",
    "        for text in X:\n",
    "            text = text.lower()  # Convert to lowercase\n",
    "            text = re.sub('[^a-zA-Z]', ' ', text)  # Keep only lowercase and uppercase letters\n",
    "            text = re.sub('\\s+', ' ', text)  # Replace multiple whitespace characters with a single space\n",
    "            text = self.tokenizer(text)  # Tokenize the text\n",
    "            X_transformed.append(text)\n",
    "        return X_transformed\n",
    "\n",
    "class TextVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vectorizer=TfidfVectorizer):\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = self.vectorizer.transform(X)\n",
    "        return X_transformed\n",
    "    \n",
    "class SentimentClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, classifier=LogisticRegression):\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classifier.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.classifier.score(X, y)\n",
    "    \n",
    "class SentimentPipeline:\n",
    "    def __init__(self, classifier=SentimentClassifier()):\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classifier.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.classifier.score(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('text_cleaner', TextPreprocessor),\n",
    "    ('vectorizer', TextVectorizer),\n",
    "    ('classifier', SentimentClassifier),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextPreprocessor.transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pipeline.fit(X_train, y_train)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\imblearn\\pipeline.py:452\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 452\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: TextPreprocessor.transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "# pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nlp_pipeline.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline,'Nlp_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = joblib.load('Nlp_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
